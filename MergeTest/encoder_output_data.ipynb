{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "from shutil import copy, rmtree\n",
    "from itertools import product\n",
    "import pdb\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from kernel.datasets import get_dataset,get_circuit_dataset,MyOwnDataset\n",
    "# from kernel.train_eval import cross_validation_with_val_set\n",
    "# from kernel.train_eval import cross_validation_without_val_set\n",
    "from kernel.train_eval import trainFEGIN\n",
    "# from kernel.gcn import *\n",
    "# from kernel.graph_sage import *\n",
    "# from kernel.gin import *\n",
    "from kernel.FEGIN import *\n",
    "# from kernel.gat import *\n",
    "# from kernel.graclus import Graclus\n",
    "# from kernel.top_k import TopK\n",
    "# from kernel.diff_pool import *\n",
    "# from kernel.global_attention import GlobalAttentionNet\n",
    "# from kernel.set2set import Set2SetNet\n",
    "# from kernel.sort_pool import SortPool\n",
    "import warnings\n",
    "import argparse\n",
    "import netlsd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.data import DenseDataLoader as DenseLoader\n",
    "from dataloader import DataLoader  # replace with custom dataloader to handle subgraphs\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data now!\n",
      "length of datalist: 7016\n",
      "saving path: MergeTest/data/processed/ltspice_examples_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "\n",
    "# import and preprocess the dataset _____________________ generate: processsed/ltspice_examples_dataset.pt    pre_filter.pt   pre_transform.pt\n",
    "dataset_name = \"ltspice_examples\"\n",
    "\n",
    "dataset = MyOwnDataset(\"MergeTest/data/\", dataset_name, \n",
    "                h = 12, # the height of rooted subgraph for NGNN models\n",
    "                node_label = \"spd\", \n",
    "                use_rd = None, \n",
    "                max_nodes_per_hop = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porcess the dataset to be compatible with the models _____________________ generate: MergeTest/data/ltspice_examples_netlsd_train.pt    MergeTest/data/ltspice_examples_netlsd_test.pt\n",
    "\n",
    "batch_size=128\n",
    "if os.path.isfile('MergeTest/data/'+dataset_name+'_netlsd_train.pt'):\n",
    "        train_des = torch.load('MergeTest/data/'+dataset_name+'_netlsd_train.pt')\n",
    "        test_des = torch.load('MergeTest/data/'+dataset_name+'_netlsd_test.pt')\n",
    "        train_dataset = [d for d in dataset if d.set =='train']\n",
    "        test_dataset = [d for d in dataset if d.set =='test']\n",
    "else:\n",
    "    train_dataset,train_des, test_dataset, test_des = [],[],[],[]\n",
    "    for index, d in enumerate(dataset):\n",
    "        if d.set=='train':\n",
    "            des = (torch.tensor(netlsd.heat(to_networkx(d, to_undirected = True)))*0.1).float()\n",
    "            des_d = Data(x = des, edge_index = d.edge_index, y = d.y)\n",
    "            train_dataset.append(d)\n",
    "            train_des.append(des_d)\n",
    "            # if index%50==0:\n",
    "            #     print(index)\n",
    "\n",
    "        else:\n",
    "            des = (torch.tensor(netlsd.heat(to_networkx(d, to_undirected = True)))*0.1).float()\n",
    "            des_d = Data(x = des, edge_index = d.edge_index, y = d.y)\n",
    "            test_des.append(des_d)\n",
    "            test_dataset.append(d)\n",
    "\n",
    "    torch.save(train_des,'MergeTest/data/'+dataset_name+'_netlsd_train.pt')\n",
    "    torch.save(test_des,'MergeTest/data/'+dataset_name+'_netlsd_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " #   porcess the dataset to be compatible with the models_____________________ generate: \n",
    "train_dataset, train_des = shuffle(train_dataset, train_des)\n",
    "\n",
    "\n",
    "if 'adj' in train_dataset[0]:\n",
    "        train_loader = DenseLoader(train_dataset, batch_size, shuffle=False)\n",
    "        test_loader = DenseLoader(test_dataset, batch_size, shuffle=False)\n",
    "else:\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "    train_loader_des = DataLoader(train_des, batch_size, shuffle=False)\n",
    "    test_loader_des = DataLoader(test_des, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    }
   ],
   "source": [
    " #   porcess the dataset to be compatible with the models_____________________ generate: \n",
    "Net = FEGIN\n",
    "model = Net(dataset, num_layers=4, hidden=32, emb_size=250,node_label = \"spd\", use_rd=False)\n",
    "model.to(device).reset_parameters()\n",
    "model.train()\n",
    "optimizer = Adam(model.parameters(), lr=1E-2, weight_decay=0)\n",
    "loader = train_loader\n",
    "des_loader = train_loader_des\n",
    "i=0\n",
    "for data,des in zip(loader,des_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        des = des.to(device)\n",
    "        out = model(data,des)\n",
    "        print(i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7266, -1.6817, -1.5722, -1.4585, -1.6303],\n",
      "        [-1.7678, -1.7215, -1.5706, -1.4220, -1.6029],\n",
      "        [-1.6850, -1.6950, -1.5810, -1.4856, -1.6153],\n",
      "        [-1.7155, -1.6933, -1.5953, -1.4415, -1.6256],\n",
      "        [-1.6984, -1.6526, -1.5710, -1.5206, -1.6142],\n",
      "        [-1.7553, -1.6697, -1.5989, -1.3848, -1.6801],\n",
      "        [-1.7459, -1.6599, -1.5845, -1.4599, -1.6192],\n",
      "        [-1.7991, -1.7069, -1.5228, -1.4666, -1.5882],\n",
      "        [-1.7086, -1.6907, -1.5636, -1.4658, -1.6388],\n",
      "        [-1.7674, -1.6996, -1.5180, -1.4518, -1.6442],\n",
      "        [-1.6514, -1.7010, -1.5410, -1.5144, -1.6523],\n",
      "        [-1.6761, -1.6723, -1.5777, -1.4978, -1.6348],\n",
      "        [-1.7155, -1.7011, -1.5722, -1.4613, -1.6188],\n",
      "        [-1.7219, -1.7160, -1.5941, -1.4378, -1.6046],\n",
      "        [-1.7211, -1.7362, -1.5713, -1.4369, -1.6119]], device='mps:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 5])\n"
     ]
    }
   ],
   "source": [
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StableDiffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
